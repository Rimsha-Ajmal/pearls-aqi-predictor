{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hfyMKnz3YAfx",
        "outputId": "68bcef5a-efec-4d2e-e74a-31f4d2921876"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting hopsworks==4.2.*\n",
            "  Downloading hopsworks-4.2.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting pyhumps==1.6.1 (from hopsworks==4.2.*)\n",
            "  Downloading pyhumps-1.6.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from hopsworks==4.2.*) (2.32.4)\n",
            "Collecting furl (from hopsworks==4.2.*)\n",
            "  Downloading furl-2.1.4-py2.py3-none-any.whl.metadata (25 kB)\n",
            "Collecting boto3 (from hopsworks==4.2.*)\n",
            "  Downloading boto3-1.40.50-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting pandas<2.2.0 (from hopsworks==4.2.*)\n",
            "  Downloading pandas-2.1.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting pyjks (from hopsworks==4.2.*)\n",
            "  Downloading pyjks-20.0.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting mock (from hopsworks==4.2.*)\n",
            "  Downloading mock-5.2.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting avro==1.11.3 (from hopsworks==4.2.*)\n",
            "  Downloading avro-1.11.3.tar.gz (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.6/90.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.12/dist-packages (from hopsworks==4.2.*) (2.0.43)\n",
            "Collecting PyMySQL[rsa] (from hopsworks==4.2.*)\n",
            "  Downloading pymysql-1.1.2-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.12/dist-packages (from hopsworks==4.2.*) (5.3.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from hopsworks==4.2.*) (2025.3.0)\n",
            "Collecting retrying (from hopsworks==4.2.*)\n",
            "  Downloading retrying-1.4.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting hopsworks_aiomysql==0.2.1 (from hopsworks_aiomysql[sa]==0.2.1->hopsworks==4.2.*)\n",
            "  Downloading hopsworks_aiomysql-0.2.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting opensearch-py<=2.4.2,>=1.1.0 (from hopsworks==4.2.*)\n",
            "  Downloading opensearch_py-2.4.2-py2.py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from hopsworks==4.2.*) (4.67.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.49.1 in /usr/local/lib/python3.12/dist-packages (from hopsworks==4.2.*) (1.75.1)\n",
            "Collecting protobuf<5.0.0,>=4.25.4 (from hopsworks==4.2.*)\n",
            "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from hopsworks==4.2.*) (25.0)\n",
            "Collecting sqlalchemy (from hopsworks==4.2.*)\n",
            "  Downloading SQLAlchemy-2.0.29-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio<2.0.0,>=1.49.1->hopsworks==4.2.*) (4.15.0)\n",
            "Requirement already satisfied: urllib3>=1.26.18 in /usr/local/lib/python3.12/dist-packages (from opensearch-py<=2.4.2,>=1.1.0->hopsworks==4.2.*) (2.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from opensearch-py<=2.4.2,>=1.1.0->hopsworks==4.2.*) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from opensearch-py<=2.4.2,>=1.1.0->hopsworks==4.2.*) (2.9.0.post0)\n",
            "Requirement already satisfied: certifi>=2022.12.07 in /usr/local/lib/python3.12/dist-packages (from opensearch-py<=2.4.2,>=1.1.0->hopsworks==4.2.*) (2025.10.5)\n",
            "Collecting numpy<2,>=1.26.0 (from pandas<2.2.0->hopsworks==4.2.*)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<2.2.0->hopsworks==4.2.*) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.12/dist-packages (from pandas<2.2.0->hopsworks==4.2.*) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->hopsworks==4.2.*) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->hopsworks==4.2.*) (3.10)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy->hopsworks==4.2.*) (3.2.4)\n",
            "Collecting botocore<1.41.0,>=1.40.50 (from boto3->hopsworks==4.2.*)\n",
            "  Downloading botocore-1.40.50-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->hopsworks==4.2.*)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.15.0,>=0.14.0 (from boto3->hopsworks==4.2.*)\n",
            "  Downloading s3transfer-0.14.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting orderedmultidict>=1.0.1 (from furl->hopsworks==4.2.*)\n",
            "  Downloading orderedmultidict-1.0.1-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting javaobj-py3 (from pyjks->hopsworks==4.2.*)\n",
            "  Downloading javaobj_py3-0.4.4-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: pyasn1>=0.3.5 in /usr/local/lib/python3.12/dist-packages (from pyjks->hopsworks==4.2.*) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.12/dist-packages (from pyjks->hopsworks==4.2.*) (0.4.2)\n",
            "Requirement already satisfied: pycryptodomex in /usr/local/lib/python3.12/dist-packages (from pyjks->hopsworks==4.2.*) (3.23.0)\n",
            "Collecting twofish (from pyjks->hopsworks==4.2.*)\n",
            "  Downloading twofish-0.3.0.tar.gz (26 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.12/dist-packages (from PyMySQL[rsa]->hopsworks==4.2.*) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography->PyMySQL[rsa]->hopsworks==4.2.*) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography->PyMySQL[rsa]->hopsworks==4.2.*) (2.23)\n",
            "Downloading hopsworks-4.2.8-py3-none-any.whl (664 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.9/664.9 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hopsworks_aiomysql-0.2.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyhumps-1.6.1-py3-none-any.whl (5.0 kB)\n",
            "Downloading opensearch_py-2.4.2-py2.py3-none-any.whl (258 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.6/258.6 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.1.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading SQLAlchemy-2.0.29-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.40.50-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading furl-2.1.4-py2.py3-none-any.whl (27 kB)\n",
            "Downloading mock-5.2.0-py3-none-any.whl (31 kB)\n",
            "Downloading pyjks-20.0.0-py2.py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.3/45.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retrying-1.4.2-py3-none-any.whl (10 kB)\n",
            "Downloading botocore-1.40.50-py3-none-any.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m104.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orderedmultidict-1.0.1-py2.py3-none-any.whl (11 kB)\n",
            "Downloading pymysql-1.1.2-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.3/45.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3transfer-0.14.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading javaobj_py3-0.4.4-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: avro, twofish\n",
            "  Building wheel for avro (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro: filename=avro-1.11.3-py2.py3-none-any.whl size=123962 sha256=772bd65255307df0298c49a932bf675e424e2b9f00b7e1bcb0f99dec3926f094\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/82/d3/8eb96fda033c7f1661086e2f8afb13f04817886d28b12f1e72\n",
            "  Building wheel for twofish (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for twofish: filename=twofish-0.3.0-cp312-cp312-linux_x86_64.whl size=24319 sha256=4e73fa912bf0eaba7c4f6152fc6e6b5d7e2da9515c4afcb747f82cb6db2a542c\n",
            "  Stored in directory: /root/.cache/pip/wheels/fa/81/02/abf836d4acb19a3de48f6bfd738cb9bcb762978b835bca2faa\n",
            "Successfully built avro twofish\n",
            "Installing collected packages: twofish, pyhumps, javaobj-py3, sqlalchemy, retrying, PyMySQL, protobuf, orderedmultidict, numpy, mock, jmespath, avro, pyjks, pandas, opensearch-py, hopsworks_aiomysql, furl, botocore, s3transfer, boto3, hopsworks\n",
            "  Attempting uninstall: sqlalchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.43\n",
            "    Uninstalling SQLAlchemy-2.0.43:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.43\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.1.4 which is incompatible.\n",
            "mizani 0.13.5 requires pandas>=2.2.0, but you have pandas 2.1.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "xarray 2025.10.1 requires pandas>=2.2, but you have pandas 2.1.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 2.1.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyMySQL-1.1.2 avro-1.11.3 boto3-1.40.50 botocore-1.40.50 furl-2.1.4 hopsworks-4.2.8 hopsworks_aiomysql-0.2.1 javaobj-py3-0.4.4 jmespath-1.0.1 mock-5.2.0 numpy-1.26.4 opensearch-py-2.4.2 orderedmultidict-1.0.1 pandas-2.1.4 protobuf-4.25.8 pyhumps-1.6.1 pyjks-20.0.0 retrying-1.4.2 s3transfer-0.14.0 sqlalchemy-2.0.29 twofish-0.3.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "e8b00551ca344f90a07f038e6ea5807b",
              "pip_warning": {
                "packages": [
                  "google",
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install hopsworks==4.2.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qosTnGvtTtk",
        "outputId": "66ff28cb-ae37-410a-a28d-b0102629887e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "API key loaded\n"
          ]
        }
      ],
      "source": [
        "import hopsworks\n",
        "from google.colab import userdata\n",
        "\n",
        "HOPSWORKS_API_KEY = userdata.get('HOPSWORKS_API_KEY')\n",
        "\n",
        "print(f'API key loaded')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uH8VHrx1vc7e",
        "outputId": "42ce474c-013a-43c6-8e82-6362df4c7aca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1251499\n",
            "✅ Connected to Hopsworks project successfully!\n"
          ]
        }
      ],
      "source": [
        "# ✅ Connect to your Hopsworks project\n",
        "project = hopsworks.login(api_key_value=HOPSWORKS_API_KEY)\n",
        "fs = project.get_feature_store()\n",
        "print(\"✅ Connected to Hopsworks project successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "olMPcNp4yDXs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def push_to_hopsworks(\n",
        "    df: pd.DataFrame,\n",
        "    fg_name: str,\n",
        "    version: int,\n",
        "    primary_key: list,\n",
        "    event_time: str,\n",
        "    description: str,\n",
        "    online_enabled: bool = False\n",
        "):\n",
        "    \"\"\"\n",
        "    Create or update a Hopsworks Feature Group and insert data.\n",
        "    \"\"\"\n",
        "\n",
        "    # Ensure datetime formatting\n",
        "    df[event_time] = pd.to_datetime(df[event_time], errors=\"coerce\", utc=True)\n",
        "    df = df.dropna(subset=[event_time])\n",
        "    df = df.reset_index(drop=True)\n",
        "\n",
        "    # Create or get feature group\n",
        "    fg = fs.get_or_create_feature_group(\n",
        "        name=fg_name,\n",
        "        version=version,\n",
        "        primary_key=primary_key,\n",
        "        event_time=event_time,\n",
        "        description=description,\n",
        "        online_enabled=online_enabled\n",
        "    )\n",
        "\n",
        "    # Insert data\n",
        "    fg.insert(df, write_options={\"wait_for_job\": True})\n",
        "    print(f\"✅ Successfully pushed {len(df)} records to feature group: '{fg_name}' (v{version})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nwS245YHaR2"
      },
      "source": [
        "# Loaded model_features_v1.csv to upload on Hopsworks (Historical data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "ldedHufD2dyp",
        "outputId": "560839cc-f994-4bc6-b514-768deb30fbf8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0f705c35-6543-48ca-99fc-8d9acfaed314\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0f705c35-6543-48ca-99fc-8d9acfaed314\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving model_features_v1.csv to model_features_v1.csv\n",
            "Data loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "print(\"Data loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCcFS0fA2cor",
        "outputId": "8c49f26f-50eb-4300-db8e-21d60fcc62b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Loaded 6577 historical records from model_features_v1.csv\n",
            "Columns: 155\n"
          ]
        }
      ],
      "source": [
        "historical_path = \"model_features_v1.csv\"\n",
        "\n",
        "df_features = pd.read_csv(historical_path)\n",
        "print(f\"✅ Loaded {len(df_features)} historical records from {historical_path}\")\n",
        "print(\"Columns:\", len(df_features.columns))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knyPZxRx3k15",
        "outputId": "3963a051-79ab-4190-ae6d-ebb8adde413c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting confluent-kafka\n",
            "  Downloading confluent_kafka-2.12.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (31 kB)\n",
            "Collecting tomli (from confluent-kafka)\n",
            "  Downloading tomli-2.3.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
            "Downloading confluent_kafka-2.12.0-cp312-cp312-manylinux_2_28_x86_64.whl (3.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomli-2.3.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (250 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.1/250.1 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tomli, confluent-kafka\n",
            "Successfully installed confluent-kafka-2.12.0 tomli-2.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install confluent-kafka"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbYbu4f7yTwp",
        "outputId": "8ce083f4-2d0e-4ef6-ba24-6126da7e17cd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading Dataframe: 100.00% |██████████| Rows 6577/6577 | Elapsed Time: 00:14 | Remaining Time: 00:00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Launching job: model_features_1_offline_fg_materialization\n",
            "Job started successfully, you can follow the progress at \n",
            "https://c.app.hopsworks.ai:443/p/1251499/jobs/named/model_features_1_offline_fg_materialization/executions\n",
            "✅ Successfully pushed 6577 records to feature group: 'model_features' (v1)\n"
          ]
        }
      ],
      "source": [
        "push_to_hopsworks(\n",
        "    df=df_features,\n",
        "    fg_name=\"model_features\",\n",
        "    version=1,\n",
        "    primary_key=[\"datetime\"],\n",
        "    event_time=\"datetime\",\n",
        "    description=\"Engineered AQI + Weather features (Karachi, hourly)\",\n",
        "    online_enabled=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmrYmhe7Hnxz"
      },
      "source": [
        "# Loaded realtime_aqi_weather.csv to upload on Hopsworks (Real-time data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "3geddtpZH0Di",
        "outputId": "9e58e8de-ece8-4303-ce03-a1e788e57b4b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e590b283-eb1c-445a-9f8c-b1f7d186688c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e590b283-eb1c-445a-9f8c-b1f7d186688c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving realtime_aqi_weather.csv to realtime_aqi_weather.csv\n",
            "Data loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "print(\"Data loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CE_dMl1BH0Nf",
        "outputId": "106e2c8b-581f-4099-8f97-7b4c5ce364c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Loaded 1 real-time records from realtime_aqi_weather.csv\n",
            "Columns: 12\n"
          ]
        }
      ],
      "source": [
        "realtime_path = \"realtime_aqi_weather.csv\"\n",
        "\n",
        "df_features = pd.read_csv(realtime_path)\n",
        "print(f\"✅ Loaded {len(df_features)} real-time records from {realtime_path}\")\n",
        "print(\"Columns:\", len(df_features.columns))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xcgCu6aeKaM4"
      },
      "outputs": [],
      "source": [
        "df_features.rename(columns={\"pm25\": \"pm2_5\"}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pxXcAE7QyA4f"
      },
      "outputs": [],
      "source": [
        "df_features[\"datetime\"] = pd.to_datetime(df_features[\"datetime\"], utc=True)\n",
        "df_features[\"datetime_str\"] = df_features[\"datetime\"].astype(str)  # string key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hDhaVzbH0SW",
        "outputId": "7249dc3e-f5c2-4cac-ab8c-0d108b5a220c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading Dataframe: 100.00% |██████████| Rows 1/1 | Elapsed Time: 00:00 | Remaining Time: 00:00\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Launching job: raw_observations_2_offline_fg_materialization\n",
            "Job started successfully, you can follow the progress at \n",
            "https://c.app.hopsworks.ai:443/p/1251499/jobs/named/raw_observations_2_offline_fg_materialization/executions\n",
            "✅ Successfully pushed 1 records to feature group: 'raw_observations' (v2)\n"
          ]
        }
      ],
      "source": [
        "push_to_hopsworks(\n",
        "    df=df_features,\n",
        "    fg_name=\"raw_observations\",\n",
        "    version=2,\n",
        "    primary_key=[\"datetime_str\"],\n",
        "    event_time=\"datetime\",\n",
        "    description=\"Real-time AQI + Weather features (Karachi, hourly)\",\n",
        "    online_enabled=True,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UskeMWrBuvE1"
      },
      "source": [
        "# Deleting the current feature group"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pgtwq9bvuatx",
        "outputId": "d8ddaa4e-c095-4bed-9401-0490923aa51e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1251499\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "JobWarning: All jobs associated to feature group `aqi_features`, version `1` will be removed.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Deleted feature group 'aqi_features'\n"
          ]
        }
      ],
      "source": [
        "project = hopsworks.login(api_key_value=HOPSWORKS_API_KEY)\n",
        "fs = project.get_feature_store()\n",
        "\n",
        "# Delete a specific feature group version\n",
        "fg = fs.get_feature_group(name=\"aqi_features\", version=1)\n",
        "fg.delete()\n",
        "\n",
        "print(\"✅ Deleted feature group 'aqi_features'\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
